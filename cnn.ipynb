{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore (train_set) AKA (train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n",
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_set)             #trainset[IMAGEINDEX][0-image_tensor,1-class] [CHANNEL][HEIGHT][WIDTH]\n",
    "print(train_set.data.shape)  #trainset.data[IMAGE INDEX][HEIGHT][WIDTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# SINGLE\n",
    "image , label = next(iter(train_set))   # SAME AS train_set[0] - train_set IS INDEXABLE\n",
    "print(image.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# BATCH\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=10)\n",
    "\n",
    "batch = next(iter(train_loader)) #CANT USE train_loader[0] - NOT INDEXABLE\n",
    "images , labels = batch          #LOADS 1 BATCH(10 images) AT ONCE\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        self.loss = F.cross_entropy\n",
    "        \n",
    "    def forward(self, t):\n",
    "        #conv layer 1\n",
    "        t = F.relu(self.conv1(t))        \n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        #conv layer 2\n",
    "        t = F.relu(self.conv2(t)) \n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        t = F.relu(self.fc1(t.reshape(-1, 12*4*4)))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t, dim=1)   #NO NEED BECAUSE LOSSFUNCTION AUTOMATICALL DOES CROSS ENTROPY\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=200)\n",
    "network = Network(lr = 0.01)\n",
    "num_epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnimishsantosh\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.8<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">wandb-run-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nimishsantosh/pytorch-course\" target=\"_blank\">https://wandb.ai/nimishsantosh/pytorch-course</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nimishsantosh/pytorch-course/runs/1osw0993\" target=\"_blank\">https://wandb.ai/nimishsantosh/pytorch-course/runs/1osw0993</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201028_160034-1osw0993</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    \"dataset\": \"FashionMNIST\",\n",
    "    \"model\": \"Custom CNN\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"batch_size\": 200,\n",
    "    \"num_epochs\": 8\n",
    "}\n",
    "\n",
    "run = wandb.init(project=\"pytorch-course\",\n",
    "                 name=\"wandb-run-2\",\n",
    "                 tags=[\"pytorch\",\"cnn\",\"fashion-mnist\"],\n",
    "                 config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  0    LOSS:  186.7149558365345\n",
      "EPOCH:  1    LOSS:  117.18891496956348\n",
      "EPOCH:  2    LOSS:  104.52210842072964\n",
      "EPOCH:  3    LOSS:  98.10501804947853\n",
      "EPOCH:  4    LOSS:  93.97693338990211\n",
      "EPOCH:  5    LOSS:  90.02866977453232\n",
      "EPOCH:  6    LOSS:  87.08223681151867\n",
      "EPOCH:  7    LOSS:  85.24627235531807\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 32335<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d161d1b7fe458b9a1dc11572e566d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.13MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.00582168873…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201028_160034-1osw0993/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201028_160034-1osw0993/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>EPOCH</td><td>7</td></tr><tr><td>LOSS</td><td>85.24627</td></tr><tr><td>_step</td><td>7</td></tr><tr><td>_runtime</td><td>199</td></tr><tr><td>_timestamp</td><td>1603881233</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>EPOCH</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>LOSS</td><td>█▃▂▂▂▁▁▁</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">wandb-run-2</strong>: <a href=\"https://wandb.ai/nimishsantosh/pytorch-course/runs/1osw0993\" target=\"_blank\">https://wandb.ai/nimishsantosh/pytorch-course/runs/1osw0993</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        images, labels = batch\n",
    "        preds = network(images)\n",
    "        loss = network.loss(preds, labels) #calc loss\n",
    "        \n",
    "        network.optimizer.zero_grad()      #set gradients to zero\n",
    "        loss.backward()                    #calc gradients\n",
    "        network.optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(\"EPOCH: \",epoch,\"   LOSS: \",total_loss)\n",
    "    wandb.log({'EPOCH': epoch, 'LOSS': total_loss})\n",
    "    \n",
    "torch.save(network.state_dict(), './models/model1.pt')\n",
    "wandb.save('./models/model1.pt')\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix / Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "tensor([9, 0, 0,  ..., 3, 0, 5])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(train_set.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "        preds = model(images)\n",
    "        \n",
    "        all_preds = torch.cat((all_preds, preds), dim=0)\n",
    "    return all_preds\n",
    "\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():      #DONT TRACK COMPUTATIONS BECAUSE WE ARENT TRAINING\n",
    "    prediction_loader = torch.utils.data.DataLoader(train_set, batch_size=10000)\n",
    "    train_preds = get_all_preds(network, prediction_loader)\n",
    "\n",
    "train_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53330\n"
     ]
    }
   ],
   "source": [
    "num_correct = get_num_correct(train_preds, train_set.targets)\n",
    "print(num_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  0.8888333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"ACCURACY: \",num_correct / len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 0, 0,  ..., 3, 0, 5])\n",
      "tensor([9, 0, 0,  ..., 3, 0, 5])\n"
     ]
    }
   ],
   "source": [
    "## FOR CONFUSION MATRIX\n",
    "matrix = torch.zeros(10,10,dtype = torch.int32)\n",
    "\n",
    "preds_argmax = train_preds.argmax(dim=1)\n",
    "print(preds_argmax)\n",
    "pred_labels = train_set.targets\n",
    "print(pred_labels)\n",
    "\n",
    "for i in range(len(preds_argmax)):\n",
    "    matrix[pred_labels[i],preds_argmax[i]] += 1 #create matrix for every predictioin,label pair increment corresponding box in matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5485,    2,   91,   79,    6,    1,  308,    0,   28,    0],\n",
       "        [  40, 5698,    0,  229,    8,    2,   11,    0,   12,    0],\n",
       "        [  68,    1, 4857,   44,  438,    1,  549,    0,   42,    0],\n",
       "        [ 198,    2,   22, 5429,  192,    0,  146,    0,   11,    0],\n",
       "        [  13,    1,  384,  164, 4795,    0,  597,    0,   46,    0],\n",
       "        [   5,    0,    0,    0,    0, 5556,    0,  175,   18,  246],\n",
       "        [1153,    4,  391,   82,  260,    1, 4008,    0,  101,    0],\n",
       "        [   0,    0,    0,    0,    0,   16,    0, 5706,    5,  273],\n",
       "        [  29,    0,    9,   15,    8,    2,   34,    4, 5899,    0],\n",
       "        [   1,    0,    0,    0,    0,    3,    0,   99,    0, 5897]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12bcc1ca0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
